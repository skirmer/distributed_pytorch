{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image Classification with PyTorch\n",
    "\n",
    "Before we explore the ways that we can use Dask's power to accelerate an image classification problem, we should discuss a little bit about the image classification process we'll be using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ImageNet and ResNet\n",
    "\n",
    "ImageNet is a powerful database of over 14 million labeled images created by academics, which lets us train neural nets for computer vision tasks. Thanks to this, scholars have been able to pretrain lots of models that are useful for general computer vision tasks, such as the one we'll use in Chapter 4. \n",
    "\n",
    "The ResNet model originates from [a 2015 publication](https://arxiv.org/abs/1512.03385), which introduces the residual learning framework for neural networks. In a residual learning neural network subsequent layers train against the residual, instead of against a completely new function - the resulting effect is that deeper layered networks are able to gain performance better than equally deep networks that are not training against the residual. If you're interested in learning more, the paper is a great resource.\n",
    "\n",
    "We won't dig in to the model much more than that, but it's interesting to know. As we are using ResNet50, our pretrained model is 50 layers.\n",
    "\n",
    "If you care to learn more about the way that computer vision and neural nets work, there are numerous great courses and books on the subject!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How We'll Use It\n",
    "\n",
    "We are going to use PyTorch for the demonstration in Chapter 4, so it's good to take a quick look at the infrastructure and how we'll be using it.\n",
    "\n",
    "\n",
    "### Model\n",
    "\n",
    "The PyTorch ecosystem handily offers computer vision datasets, transformation tools, and prebuilt models in the `torchvision` library, which we'll use here to load ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "resnet = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Datasets\n",
    "\n",
    "You can load the images you want directly from S3 or another cloud storage system - we're using a public S3 bucket on AWS, where the Stanford Dogs dataset has been placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from PIL import Image\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "with s3.open(\"s3://saturn-public-data/dogs/2-dog.jpg\", 'rb') as f:\n",
    "    img = Image.open(f).convert(\"RGB\")\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(250), \n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference Task\n",
    "\n",
    "Finally, we create a function that runs through the inference task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "def classify_img(transform, img, model):\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "    resnet.eval()\n",
    "    out = model(batch_t)\n",
    "    \n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "    labelset = [(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]\n",
    "    return to_pil(img_t), labelset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Key aspects of the function to pay attention to include:\n",
    "\n",
    "* `img_t = transform(img)` : we must run the transformation we defined above on every image before we try to classify it.  \n",
    "* `batch_t = torch.unsqueeze(img_t, 0)` : this step reshapes our image tensors to allow the model to accept it.\n",
    "* `resnet.eval()` : When we download the model, it can either be in training or in evaluation mode. We need it in evaluation mode here, so that it can return the predicted labels to us without changing itself.\n",
    "* `out = model(batch_t)` : This step actually evaluates the images. We are using batches of images here, so many can be classified at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Results Processing\n",
    "\n",
    "* `_, indices = torch.sort(out, descending=True)` : Sorts the results, high score to low (gives us the most likely labels at the top).\n",
    "* `percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100` : Rescales the scores from the model to probabilities (returns probabilities of each label) .\n",
    "* `labelset = [(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]` : Interprets the top five labels in human readable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def classify_img(transform, img, model):\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "    resnet.eval()\n",
    "    out = model(batch_t)\n",
    "    \n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "    labelset = [(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]\n",
    "    return to_pil(img_t), labelset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running the Classification\n",
    "\n",
    "We just have to run the function at this point, and we'll get human readable results as well as an image we can look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dogpic, labels = classify_img(transform, img, resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dogpic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have proved our image classification can run on a single image and is effective! This sets us up to complete our case study, translating this use case to a highly parallel job on a Dask cluster."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "dask_kernel",
   "language": "python",
   "name": "dask_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
